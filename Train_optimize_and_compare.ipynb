{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA LOADING AND SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../data/train.csv')\n",
    "test=pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below the provided train data is being split into train and val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Survived']\n",
    "X = train.drop(columns=['PassengerId', 'Survived', 'Ticket', 'Cabin'])\n",
    "X_test = test[['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#survived:      Survival            0 = No, 1 = Yes\n",
    "#PassengerId:   Unique Id\n",
    "#pclass:        Ticket class        1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "#sex:           Sex\n",
    "#Age:           Age in years \n",
    "#SibSp:         # of siblings / spouses aboard the Titanic\n",
    "#parch:         # of parents / children aboard the Titanic\n",
    "#ticket:        Ticket number \n",
    "#fare:          Passenger fare \n",
    "#cabin:         Cabin number \n",
    "#embarked:      Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below two new features ('FamilySize' and 'IsAlone') are made based on two existing features ('SibSp' and 'Parch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETERMINE FAMILIY SIZE\n",
    "\n",
    "data = [X_train, X_val, X_test]\n",
    "for dataset in data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch']\n",
    "    dataset.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "    dataset['IsAlone'] = 1\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below a new feature ('Title') is created based on the feature 'Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACT TITLES FROM Name COLUMN\n",
    "\n",
    "data = [X_train, X_val, X_test]\n",
    "for dataset in data:\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    dataset.drop(['Name'], axis=1, inplace=True)\n",
    "    dataset['Title'].loc[dataset['Title'] == 'Miss'] = 'Mrs'\n",
    "    rare_titles = dataset.Title.value_counts() < 10\n",
    "    dataset['Title'] = dataset.Title.apply(lambda x: 'rare' if rare_titles[x] else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE TO PERFOM IMPUTATION, ONE-HOT ENCODING AND PRINCIPAL COMPONENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below two pipelines are created with different combination of transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PIPELINE FOR CATEGORICAL DATA\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    ('pca', PCA(n_components=10))\n",
    "])\n",
    "\n",
    "### PIPELINE FOR NUMERICAL DATA\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below two different groups of columns are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Pclass', 'Sex', 'Embarked', 'IsAlone', 'Title']\n",
    "\n",
    "numerical_columns = ['Age', 'Fare', 'FamilySize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROCESSING DATA BY PACKING TWO PIPELINES VIA COLUMNTRANSFORMER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below a specific ColumnTransformer is created, which is combining two different transformer pipelines for two different column groups, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_transformer, numerical_columns),\n",
    "        ('categorical', categorical_transformer, categorical_columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL PIPELINE TO INCLUDE THE CLASSIFIER MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below seven different pipelines are created to perform data preprocessing and subsequently, training a specific estimator. A list is created at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest:\n",
    "\n",
    "clf_rfc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "\n",
    "### Logistic Regression:\n",
    "\n",
    "clf_lor = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "### Stochastic Gradient Descent (SGD):\n",
    "\n",
    "clf_sgdc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGDClassifier(max_iter=5, tol=None))\n",
    "])\n",
    "\n",
    "### K Nearest Neighbor:\n",
    "\n",
    "clf_knc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=3))\n",
    "])\n",
    "\n",
    "### Gaussian Naive Bayes:\n",
    "\n",
    "clf_gnb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "### Perceptron:\n",
    "\n",
    "clf_per = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', Perceptron(max_iter=5))\n",
    "])\n",
    "\n",
    "### Linear Support Vector Machine:\n",
    "\n",
    "clf_lsvc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LinearSVC())\n",
    "])\n",
    "\n",
    "### Decision Tree:\n",
    "\n",
    "clf_dtc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "model_pipelines = [clf_rfc, clf_lor, clf_sgdc, clf_knc, clf_gnb, clf_per, clf_lsvc, clf_dtc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A loop is created to perform the following using each pipline from the model_pipeleines list.\n",
    "- It trains an estimator\n",
    "- It calculates accuracies for train and val data\n",
    "- It calculates cross_val_score using train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accu(train)</th>\n",
       "      <th>Accu(val)</th>\n",
       "      <th>cv_mean_Accu(train)</th>\n",
       "      <th>cv_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier(max_iter=5, tol=None)</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron(max_iter=5)</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC()</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  Accu(train)  Accu(val)  \\\n",
       "0             RandomForestClassifier()        0.986      0.810   \n",
       "1                 LogisticRegression()        0.839      0.810   \n",
       "2  SGDClassifier(max_iter=5, tol=None)        0.615      0.593   \n",
       "3  KNeighborsClassifier(n_neighbors=3)        0.883      0.810   \n",
       "4                         GaussianNB()        0.795      0.806   \n",
       "5               Perceptron(max_iter=5)        0.730      0.728   \n",
       "6                          LinearSVC()        0.836      0.810   \n",
       "7             DecisionTreeClassifier()        0.986      0.772   \n",
       "\n",
       "   cv_mean_Accu(train)  cv_score_std  \n",
       "0                0.790         0.035  \n",
       "1                0.828         0.022  \n",
       "2                0.740         0.066  \n",
       "3                0.799         0.023  \n",
       "4                0.783         0.022  \n",
       "5                0.713         0.090  \n",
       "6                0.836         0.023  \n",
       "7                0.767         0.021  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for pipeline in model_pipelines:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    accuracy_train = round(pipeline.score(X_train, y_train), 3)\n",
    "    accuracy_val = round(pipeline.score(X_val, y_val), 3)\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean_accuracy_train = round(cv_scores.mean(),3)\n",
    "    cv_std_accuracy_train = round(cv_scores.std(), 3)\n",
    "    scores.append((str(pipeline[1]), accuracy_train, accuracy_val, cv_mean_accuracy_train, cv_std_accuracy_train))\n",
    "\n",
    "\n",
    "model_specific_scores = pd.DataFrame(scores, columns=['Model', 'Accu(train)', 'Accu(val)', 'cv_mean_Accu(train)',\n",
    "                                                      'cv_score_std'])\n",
    "model_specific_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Different dictionaries are created for each pipeline created above with a set of parameters as keys and a list of parameter settings as values. A list of dictionaries is created at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer_dist = {'preprocessor__numerical__imputer__n_neighbors': list(range(2, 15)),\n",
    "                              'preprocessor__numerical__imputer__add_indicator': [True, False]}\n",
    "categorical_transformer_dist = {'preprocessor__categorical__imputer__strategy': ['most_frequent', 'constant'],\n",
    "                                'preprocessor__categorical__imputer__add_indicator': [True, False],\n",
    "                                'preprocessor__categorical__pca__n_components': list(range(2, 15))}\n",
    "rfc_dist = {'classifier__bootstrap': [True, False],\n",
    "            'classifier__max_depth': list(range(2, 20)),\n",
    "            'classifier__n_estimators': list(range(50, 500))}\n",
    "\n",
    "lor_dist = {'classifier__C': [100, 10, 1.0, 0.1, 0.01],\n",
    "            'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            'classifier__penalty': ['none', 'l1', 'l2', 'elasticnet']}\n",
    "\n",
    "sgdc_dist = {\"classifier__n_iter_no_change\": [1, 5, 10],\n",
    "             \"classifier__alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             \"classifier__penalty\": ['l1', 'l2', 'elasticnet']}\n",
    "\n",
    "knc_dist = {\"classifier__leaf_size\": list(range(1,50)),\n",
    "            \"classifier__n_neighbors\": list(range(1,30)),\n",
    "            \"classifier__p\": [1,2]}\n",
    "\n",
    "gnb_dist = {'classifier__var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "per_dist = {\"classifier__penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "            \"classifier__alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "lsvc_dist = {'classifier__C': [0.1,1, 10, 100],\n",
    "             \"classifier__penalty\": ['l1', 'l2'],\n",
    "             'classifier__loss': ['hinge', 'squared_hinge']}\n",
    "\n",
    "dtc_dist = {'classifier__criterion': ['gini', 'entropy'],\n",
    "            'classifier__max_depth': [2,4,6,8,10,12]}\n",
    "\n",
    "model_params = [rfc_dist, lor_dist, sgdc_dist, knc_dist, gnb_dist, per_dist, lsvc_dist, dtc_dist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A loop is created to perform hyper-parameter optimization using RandomizedSearchCV for each model specific pipeline and corresponding parameter dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It implements RandomizedSearchCV\n",
    "- It calculates mean cross-validation score\n",
    "- It extracts the best parameter settings only based on what were given as input\n",
    "- obtained best_estimator settings are used to train an estimator again\n",
    "- Accuracies are calculated while using train and val data\n",
    "- It calculates cross_val_score using train data (This step is not necessary as the best_score_ already provides mean cross-validated score of the best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_parameters</th>\n",
       "      <th>Accu_new(train)</th>\n",
       "      <th>Accu_new(val)</th>\n",
       "      <th>cv_mean_Accu_new(train)</th>\n",
       "      <th>cv_score_std_new(val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>{'preprocessor__numerical__imputer__n_neighbor...</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>{'preprocessor__numerical__imputer__n_neighbor...</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier(max_iter=5, tol=None)</td>\n",
       "      <td>{'preprocessor__numerical__imputer__n_neighbor...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>{'preprocessor__numerical__imputer__n_neighbor...</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>{'preprocessor__numerical__imputer__n_neighbor...</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron(max_iter=5)</td>\n",
       "      <td>{'preprocessor__numerical__imputer__n_neighbor...</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC()</td>\n",
       "      <td>{'preprocessor__numerical__imputer__n_neighbor...</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>{'preprocessor__numerical__imputer__n_neighbor...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0             RandomForestClassifier()   \n",
       "1                 LogisticRegression()   \n",
       "2  SGDClassifier(max_iter=5, tol=None)   \n",
       "3  KNeighborsClassifier(n_neighbors=3)   \n",
       "4                         GaussianNB()   \n",
       "5               Perceptron(max_iter=5)   \n",
       "6                          LinearSVC()   \n",
       "7             DecisionTreeClassifier()   \n",
       "\n",
       "                                     Best_parameters  Accu_new(train)  \\\n",
       "0  {'preprocessor__numerical__imputer__n_neighbor...            0.888   \n",
       "1  {'preprocessor__numerical__imputer__n_neighbor...            0.849   \n",
       "2  {'preprocessor__numerical__imputer__n_neighbor...            0.825   \n",
       "3  {'preprocessor__numerical__imputer__n_neighbor...            0.823   \n",
       "4  {'preprocessor__numerical__imputer__n_neighbor...            0.807   \n",
       "5  {'preprocessor__numerical__imputer__n_neighbor...            0.669   \n",
       "6  {'preprocessor__numerical__imputer__n_neighbor...            0.838   \n",
       "7  {'preprocessor__numerical__imputer__n_neighbor...            0.865   \n",
       "\n",
       "   Accu_new(val)  cv_mean_Accu_new(train)  cv_score_std_new(val)  \n",
       "0          0.802                    0.825                  0.026  \n",
       "1          0.799                    0.838                  0.022  \n",
       "2          0.802                    0.823                  0.032  \n",
       "3          0.806                    0.828                  0.011  \n",
       "4          0.799                    0.807                  0.015  \n",
       "5          0.701                    0.779                  0.047  \n",
       "6          0.810                    0.840                  0.029  \n",
       "7          0.810                    0.832                  0.030  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_values = []\n",
    "for i in range(len(model_params)):\n",
    "    #print(model_params[i])\n",
    "    '''\n",
    "    performing randomized search on hyper parameters and noting best score, which is a mean\n",
    "    cross-validated score of the best_estimator, and best parameters\n",
    "    '''\n",
    "    param_dist = {**numerical_transformer_dist, **categorical_transformer_dist, **model_params[i]}\n",
    "    rscv = RandomizedSearchCV(model_pipelines[i], param_distributions=param_dist, n_iter=100)\n",
    "    rscv.fit(X_train, y_train)\n",
    "    #rscv_best_score = round(rscv.best_score_, 3) *** \n",
    "    best_parameters = rscv.best_params_\n",
    "    '''\n",
    "    training the estimator again with best best parameter setting to get scores for comparing\n",
    "    '''\n",
    "    model_best = rscv.best_estimator_\n",
    "    model_best.fit(X_train, y_train)\n",
    "    model_new_train_score = round(model_best.score(X_train, y_train), 3)\n",
    "    model_new_val_score = round(model_best.score(X_val, y_val), 3)\n",
    "    \n",
    "    '''\n",
    "    performing cross-validation again with best estimator setting to get scores for comparing\n",
    "    '''\n",
    "    cv_scores_with_best_params = cross_val_score(model_best, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_best_param_mean_accuracy_train = round(cv_scores_with_best_params.mean(),3)\n",
    "    cv_best_param_std_accuracy_train = round(cv_scores_with_best_params.std(), 3)\n",
    "    '''\n",
    "    making predictions with best_estimator and writing out a .csv file uploading it to kaggle\n",
    "    '''\n",
    "    ypred = model_best.predict(X_test)\n",
    "    output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': ypred})\n",
    "    output.to_csv(\"pred_{}.csv\".format(str(model_pipelines[i][1]).split('()')[0]), index=False)\n",
    "    '''\n",
    "    updating the created empty dictionary 'best_params' with different scores and best parameters for each estimator\n",
    "    '''\n",
    "    best_values.append((str(model_pipelines[i][1]), best_parameters, model_new_train_score, \n",
    "                       model_new_val_score, cv_best_param_mean_accuracy_train,\n",
    "                       cv_best_param_std_accuracy_train))\n",
    "\n",
    "best_values_df = pd.DataFrame(best_values, columns=['Model', 'Best_parameters', 'Accu_new(train)', 'Accu_new(val)',\n",
    "                                                    'cv_mean_Accu_new(train)', 'cv_score_std_new(val)'])\n",
    "best_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accu(train)</th>\n",
       "      <th>cv_mean_Accu(train)</th>\n",
       "      <th>Accu_new(train)</th>\n",
       "      <th>cv_mean_Accu_new(train)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC()</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier(max_iter=5, tol=None)</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron(max_iter=5)</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  Accu(train)  cv_mean_Accu(train)  \\\n",
       "6                          LinearSVC()        0.836                0.836   \n",
       "1                 LogisticRegression()        0.839                0.828   \n",
       "7             DecisionTreeClassifier()        0.986                0.767   \n",
       "3  KNeighborsClassifier(n_neighbors=3)        0.883                0.799   \n",
       "0             RandomForestClassifier()        0.986                0.790   \n",
       "2  SGDClassifier(max_iter=5, tol=None)        0.615                0.740   \n",
       "4                         GaussianNB()        0.795                0.783   \n",
       "5               Perceptron(max_iter=5)        0.730                0.713   \n",
       "\n",
       "   Accu_new(train)  cv_mean_Accu_new(train)  \n",
       "6            0.838                    0.840  \n",
       "1            0.849                    0.838  \n",
       "7            0.865                    0.832  \n",
       "3            0.823                    0.828  \n",
       "0            0.888                    0.825  \n",
       "2            0.825                    0.823  \n",
       "4            0.807                    0.807  \n",
       "5            0.669                    0.779  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accu_before = model_specific_scores[['Model', 'Accu(train)', 'cv_mean_Accu(train)']]\n",
    "Accu_after = best_values_df[['Model', 'Accu_new(train)', 'cv_mean_Accu_new(train)']]\n",
    "compare_accu_df = Accu_before.merge(Accu_after)\n",
    "compare_accu_df.sort_values(by=['cv_mean_Accu_new(train)'], ascending=False)\n",
    "#Accu_before\n",
    "#Accu_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION\n",
    "- Above table shows that the difference between accuracy and the mean accuracy after cross-validation is larger in many cases campared to that after optimization, which highlights the usefulness of hyper-parameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
